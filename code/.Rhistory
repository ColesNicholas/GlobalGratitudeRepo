# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
# Change the 'incentive' column from "volunteer" to "paid" for NOR_01 participants after 11/19/2024
data <- data %>%
mutate(incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("2024-11-19 00:00:00"),
"paid", incentive))
View(data)
mutate(incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 00:00"),
"paid", incentive))
data$lab
data <- data %>%
mutate(incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 00:00"),
"paid", incentive))
data <- data %>%
mutate(incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00"),
"paid", incentive))
data <- data %>%
mutate(incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00"),
"paid", incentive))
data <- data %>%
mutate(StartDate = as.POSIXct(StartDate, format = "%m/%d/%Y %H:%M"),  # Ensure correct format
incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00", format = "%m/%d/%Y %H:%M"),
"paid", incentive))
write.csv(data,
file = here('data',
"GlobalGratitude_Final_Cleaned.csv"))
unique(data$lab)
unique(data$Progress)
data <- data %>%
#Removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
# fix known issues
data <- data %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK"
# Change the 'incentive' column from "volunteer" to "paid" for NOR_01 participants after 11/19/2024
data <- data %>%
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
# fix known issues
data <- data %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
data <- data %>%
mutate(StartDate = as.POSIXct(StartDate, format = "%m/%d/%Y %H:%M"),  # Ensure correct format
incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00", format = "%m/%d/%Y %H:%M"),
"paid", incentive))
# Save the processed data to CSV
write.csv(data,
file = here('data',
"GlobalGratitude_Final_Cleaned.csv"))
data <- read.csv(file = here("data", "GlobalGratitude_Final_Cleaned.csv"))
View(data)
data_main <- read.csv(file = here("data", "GlobalGratitude_Final.csv"))
data_main <- data_main %>%
rename("StartDate" = "ï..StartDate")
data_main <- data_main %>% select(StartDate:gov_leaders_6, meals_attention:pageNo)
# Fetch the USA_02b (harmonized) survey data
data_USA_02b <- read.csv(file = here("data", "USA_02b_raw_harmonized.csv"))
data_USA_02b <- data_USA_02b %>%
rename("events_list" = "control_list")
# Fetch the USA_02c survey data
data_USA_02c <- read.csv(file = here("data", "USA_02c.csv"))
data_USA_02c <- data_USA_02c %>% select(StartDate:gov_leaders_6, meals_attention:pageNo)
#Match columns
data_main <- data_main %>%
mutate(across(names(data_USA_02c), ~ {
# Matching character columns
if (is.character(data_USA_02c[[cur_column()]])) {
return(as.character(.))
}
# Matching numeric or integer columns
else if (is.numeric(data_USA_02c[[cur_column()]])) {
return(as.numeric(.))
}
else {
return(.)
}
}))
# Read and combine the CSV files
data <- bind_rows(data_main, data_USA_02c)
data <- bind_rows(data, data_USA_02b)
data_USA_02c <- data_USA_02c %>%
#Removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
data_USA_02b <- data_USA_02b %>%
#Removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
#Clean data
data_main <- data_main %>%
#Removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
data_2 <- bind_rows(data_main, data_USA_02c)
data_2 <- bind_rows(data_2, data_USA_02b)
data <- data %>%
#Removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
# fix known issues
data <- data %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
data <- read.csv(file = here("data", "GlobalGratitude_Final_Cleaned.csv"))
library(dplyr)
library(here)
# specify directory
i_am("code/GlobalGratitude_LabSpecificData.Rmd")
#Fetch main survey data
data_main <- read.csv(file = here("data", "GlobalGratitude_Final.csv"))
data_main <- data_main %>%
rename("StartDate" = "ï..StartDate")
data_main <- data_main %>% select(StartDate:gov_leaders_6, meals_attention:pageNo)
# Fetch the USA_02b (harmonized) survey data
data_USA_02b <- read.csv(file = here("data", "USA_02b_raw_harmonized.csv"))
data_USA_02b <- data_USA_02b %>%
rename("events_list" = "control_list")
# Fetch the USA_02c survey data
data_USA_02c <- read.csv(file = here("data", "USA_02c.csv"))
data_USA_02c <- data_USA_02c %>% select(StartDate:gov_leaders_6, meals_attention:pageNo)
#Match columns
data_main <- data_main %>%
mutate(across(names(data_USA_02c), ~ {
# Matching character columns
if (is.character(data_USA_02c[[cur_column()]])) {
return(as.character(.))
}
# Matching numeric or integer columns
else if (is.numeric(data_USA_02c[[cur_column()]])) {
return(as.numeric(.))
}
else {
return(.)
}
}))
# Read and combine the CSV files
data <- bind_rows(data_main, data_USA_02c)
data <- bind_rows(data, data_USA_02b)
#Clean data
data <- data %>%
#Removed test links and incomplete surveys
filter(DistributionChannel != "preview",
consent == 1,
Progress >= 95,
lab != "",
condition_type != "NA",
lab != "NA")
# fix known issues
data <- data %>%
# 4/22/2024 TUR_01 used real link for testing purposes
filter(ResponseId != "R_42KUGZSS76NgWH7",
ResponseId != "R_4W4EXfgeyk1rCYF",
ResponseId != "R_45Z862EIfzYcin4",
ResponseId != "R_7BhJx9Ci7THupmF",
ResponseId != "R_42Lv9fg5qi9V9xm",
ResponseId != "R_2kFa26mh78uevnz",
ResponseId != "R_4DRThnH8LgbEvM8",
ResponseId != "R_4r1kAEqQCo1PNn6",
ResponseId != "R_4GQErqyYDlRWVwZ",
ResponseId != "R_4SGF0GCHSHIN0ls",
ResponseId != "R_6Pndj5c7sr1pcU3",
ResponseId != "R_8lQxsY2ITg7HKh1",
ResponseId != "R_8HXsI5PQftiJUYk",
ResponseId != "R_8iVWI3CN49ACiUp",
#6/6/2024 Removed USA_01 duplicate data
ResponseId != "R_6rDfD5u84z6WufT",
#11/21/2024 Removed DZA_01 test data
ResponseId != "R_4ioYJK1zR2FgR4R",
ResponseId != "R_4OvlyOmeTsmLpFn",
ResponseId != "R_4BA1gbglSYnVyDK")
# Change the 'incentive' column from "volunteer" to "paid" for NOR_01 participants after 11/19/2024
data <- data %>%
mutate(StartDate = as.POSIXct(StartDate, format = "%m/%d/%Y %H:%M"),  # Ensure correct format
incentive = if_else(lab == "NOR_01" & StartDate > as.POSIXct("11/19/2024 0:00", format = "%m/%d/%Y %H:%M"),
"paid", incentive))
# Save the processed data to CSV
write.csv(data,
file = here('data',
"GlobalGratitude_Final_Cleaned.csv"))
data <- read.csv(file = here("data", "GlobalGratitude_Final_Cleaned.csv"))
data$gratitude_all <- rowMeans(data[, c("grateful", "thankful", "appreciative")], na.rm = TRUE)
data$happy_all <- rowMeans(data[, c("happy", "satisfied", "content", "joyful", "pleased")], na.rm = TRUE)
data$sad_all <- rowMeans(data[, c("sad", "depressed", "anxious", "nervous")], na.rm = TRUE)
data$ls_all <- rowMeans(data[, c("ls_1", "ls_2", "ls_3", "ls_4", "ls_5")], na.rm = TRUE)
#Remove data without a mean dependent score
data <- data %>%
filter(gratitude_all != "NaN",
happy_all != "NaN",
sad_all != "NaN",
ls_all != "NaN")
data$condition_type <- factor(data$condition_type, levels = c("control", "intervention"))
data$condition_type <- relevel(data$condition_type, ref = "intervention")
data <- data %>%
mutate(country = case_when(
lab == "POL_01" ~ "Poland",
lab == "POL_02" ~ "Poland",
lab == "DNK_01" ~ "Denmark",
lab == "TUR_01" ~ "Turkey",
lab == "MYS_01" ~ "Malaysia",
lab == "USA_01" ~ "United States",
lab == "USA_02" ~ "United States",
lab == "USA_02b" ~ "United States",
lab == "USA_02c" ~ "United States",
lab == "NGA_01" ~ "Nigeria",
lab == "NGA_02" ~ "Nigeria",
lab == "CAN_01" ~ "Canada",
lab == "FRA_01" ~ "France",
lab == "AUS_01" ~ "Australia",
lab == "CHL_01" ~ "Chile",
lab == "DEU_01" ~ "Germany",
lab == "GRC_01" ~ "Greece",
lab == "HUN_01" ~ "Hungary",
lab == "ISR_01" ~ "Israel",
lab == "IRL_01" ~ "Ireland",
lab == "MEX_01" ~ "Mexico",
lab == "ITA_01" ~ "Italy",
lab == "PRT_01" ~ "Portugal",
lab == "BRA_01" ~ "Brazil",
lab == "NLD_01" ~ "Netherlands",
lab == "GBR_01" ~ "United Kingdom",
lab == "ESP_01" ~ "Spain",
lab == "ZAF_01" ~ "South Africa",
lab == "KOR_01" ~ "South Korea",
lab == "SWE_01" ~ "Sweden",
lab == "IND_01" ~ "India",
lab == "COL_01" ~ "Colombia",
lab == "CHN_01" ~ "China",
lab == "KAZ_01" ~ "Kazakhstan",
lab == "NOR_01" ~ "Norway",
lab == "JPN_01" ~ "Japan",
lab == "GHA_01" ~ "Ghana",
lab == "THA_01" ~ "Thailand",
TRUE ~ NA_character_
))
control_data <- subset(data, condition_type == "control")
intervention_data <- subset(data, condition_type == "intervention")
unique_labs <- unique(data$country)
condition_names <- c("list", "letter", "text", "hk.list", "sub", "god.letter")
results_df <- data.frame(
lab = character(),
test = character(),
grat_t_statistic = numeric(),
grat_p_value = numeric(),
grat_effect_size = numeric(),
grat_standard_error = numeric(),
pa_t_statistic = numeric(),
pa_p_value = numeric(),
pa_effect_size = numeric(),
pa_standard_error = numeric(),
na_t_statistic = numeric(),
na_p_value = numeric(),
na_effect_size = numeric(),
na_standard_error = numeric(),
ls_t_statistic = numeric(),
ls_p_value = numeric(),
ls_effect_size = numeric(),
ls_standard_error = numeric(),
stringsAsFactors = FALSE
)
results_list <- sapply(unique_labs, function(lab_name){
# Subset data for the current lab
lab_data <- subset(data, country == lab_name)
# Count observations for each condition type
condition_counts <- table(lab_data$condition_type)
# Calculate t-test
grat_t_test_result <- t.test(gratitude_all ~ condition_type, data = lab_data)
pa_t_test_result <- t.test(happy_all ~ condition_type, data = lab_data)
na_t_test_result <- t.test(sad_all ~ condition_type, data = lab_data)
ls_t_test_result <- t.test(ls_all ~ condition_type, data = lab_data)
# Calculate Cohen's d effect size
grat_effect_size_result <- cohen.d(gratitude_all ~ condition_type, data = lab_data)
pa_effect_size_result <- cohen.d(happy_all ~ condition_type, data = lab_data)
na_effect_size_result <- cohen.d(sad_all ~ condition_type, data = lab_data)
ls_effect_size_result <- cohen.d(ls_all ~ condition_type, data = lab_data)
# Calculate variances and counts for each group
grat_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$gratitude_all[lab_data$condition_type == cond], na.rm = TRUE))
pa_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$happy_all[lab_data$condition_type == cond], na.rm = TRUE))
na_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$sad_all[lab_data$condition_type == cond], na.rm = TRUE))
ls_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$ls_all[lab_data$condition_type == cond], na.rm = TRUE))
ns <- sapply(levels(lab_data$condition_type), function(cond) sum(lab_data$condition_type == cond))
# Calculate pooled standard error
grat_standard_error <- sqrt((grat_vars["intervention"] / ns["intervention"]) + (grat_vars["control"] / ns["control"]))
pa_standard_error <- sqrt((pa_vars["intervention"] / ns["intervention"]) + (pa_vars["control"] / ns["control"]))
na_standard_error <- sqrt((na_vars["intervention"] / ns["intervention"]) + (na_vars["control"] / ns["control"]))
ls_standard_error <- sqrt((ls_vars["intervention"] / ns["intervention"]) + (ls_vars["control"] / ns["control"]))
# Store the results in the data frame
result <- data.frame(
lab = lab_name,
test = "All Interventions",
grat_t_statistic = grat_t_test_result$statistic,
grat_p_value = grat_t_test_result$p.value,
grat_effect_size = grat_effect_size_result$estimate,
grat_standard_error = grat_standard_error,
pa_t_statistic = pa_t_test_result$statistic,
pa_p_value = pa_t_test_result$p.value,
pa_effect_size = pa_effect_size_result$estimate,
pa_standard_error = pa_standard_error,
na_t_statistic = na_t_test_result$statistic,
na_p_value = na_t_test_result$p.value,
na_effect_size = na_effect_size_result$estimate,
na_standard_error = na_standard_error,
ls_t_statistic = ls_t_test_result$statistic,
ls_p_value = ls_t_test_result$p.value,
ls_effect_size = ls_effect_size_result$estimate,
ls_standard_error = ls_standard_error,
stringsAsFactors = FALSE
)
return(result)
}, simplify = FALSE)
library(dplyr)
library(effsize)
library(ggplot2)
library(qualtRics)
library(metafor)
library(scales)
library(ggtext)
library(RColorBrewer)
library(rnaturalearth)
library(Matrix)
library(ggtext)
library(tidyr)
library(sf)
results_df <- data.frame(
lab = character(),
test = character(),
grat_t_statistic = numeric(),
grat_p_value = numeric(),
grat_effect_size = numeric(),
grat_standard_error = numeric(),
pa_t_statistic = numeric(),
pa_p_value = numeric(),
pa_effect_size = numeric(),
pa_standard_error = numeric(),
na_t_statistic = numeric(),
na_p_value = numeric(),
na_effect_size = numeric(),
na_standard_error = numeric(),
ls_t_statistic = numeric(),
ls_p_value = numeric(),
ls_effect_size = numeric(),
ls_standard_error = numeric(),
stringsAsFactors = FALSE
)
results_list <- sapply(unique_labs, function(lab_name){
# Subset data for the current lab
lab_data <- subset(data, country == lab_name)
# Count observations for each condition type
condition_counts <- table(lab_data$condition_type)
# Calculate t-test
grat_t_test_result <- t.test(gratitude_all ~ condition_type, data = lab_data)
pa_t_test_result <- t.test(happy_all ~ condition_type, data = lab_data)
na_t_test_result <- t.test(sad_all ~ condition_type, data = lab_data)
ls_t_test_result <- t.test(ls_all ~ condition_type, data = lab_data)
# Calculate Cohen's d effect size
grat_effect_size_result <- cohen.d(gratitude_all ~ condition_type, data = lab_data)
pa_effect_size_result <- cohen.d(happy_all ~ condition_type, data = lab_data)
na_effect_size_result <- cohen.d(sad_all ~ condition_type, data = lab_data)
ls_effect_size_result <- cohen.d(ls_all ~ condition_type, data = lab_data)
# Calculate variances and counts for each group
grat_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$gratitude_all[lab_data$condition_type == cond], na.rm = TRUE))
pa_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$happy_all[lab_data$condition_type == cond], na.rm = TRUE))
na_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$sad_all[lab_data$condition_type == cond], na.rm = TRUE))
ls_vars <- sapply(levels(lab_data$condition_type), function(cond) var(lab_data$ls_all[lab_data$condition_type == cond], na.rm = TRUE))
ns <- sapply(levels(lab_data$condition_type), function(cond) sum(lab_data$condition_type == cond))
# Calculate pooled standard error
grat_standard_error <- sqrt((grat_vars["intervention"] / ns["intervention"]) + (grat_vars["control"] / ns["control"]))
pa_standard_error <- sqrt((pa_vars["intervention"] / ns["intervention"]) + (pa_vars["control"] / ns["control"]))
na_standard_error <- sqrt((na_vars["intervention"] / ns["intervention"]) + (na_vars["control"] / ns["control"]))
ls_standard_error <- sqrt((ls_vars["intervention"] / ns["intervention"]) + (ls_vars["control"] / ns["control"]))
# Store the results in the data frame
result <- data.frame(
lab = lab_name,
test = "All Interventions",
grat_t_statistic = grat_t_test_result$statistic,
grat_p_value = grat_t_test_result$p.value,
grat_effect_size = grat_effect_size_result$estimate,
grat_standard_error = grat_standard_error,
pa_t_statistic = pa_t_test_result$statistic,
pa_p_value = pa_t_test_result$p.value,
pa_effect_size = pa_effect_size_result$estimate,
pa_standard_error = pa_standard_error,
na_t_statistic = na_t_test_result$statistic,
na_p_value = na_t_test_result$p.value,
na_effect_size = na_effect_size_result$estimate,
na_standard_error = na_standard_error,
ls_t_statistic = ls_t_test_result$statistic,
ls_p_value = ls_t_test_result$p.value,
ls_effect_size = ls_effect_size_result$estimate,
ls_standard_error = ls_standard_error,
stringsAsFactors = FALSE
)
return(result)
}, simplify = FALSE)
unique(data$condition_type)
unique(data$gratitude_all)
